{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "8mpfRKzJNL_V",
        "colab_type": "code",
        "outputId": "a8b3518a-3c2d-4670-e76e-2f1ee8c8812f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import string\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import keras\n",
        "import io\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from sklearn import random_projection\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from keras.models import Sequential, Input, Model\n",
        "from keras.layers import Embedding, Dense, Dropout, LSTM, Concatenate, CuDNNLSTM, Conv2D, Reshape, MaxPool2D, Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras import metrics\n",
        "import datetime\n",
        "\n",
        "stop_words = set(stopwords.words('english') + list(string.punctuation))\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "folder_id = '1pQymPM0o_hYssoMvmLonRi5SNpUeOp0j'\n",
        "params = {}\n",
        "children = drive_service.files().list(q=\"'\" + folder_id + \"' in parents\").execute()\n",
        "for child in children.get('files', []):\n",
        "  file_id = child['id']\n",
        "  request = drive_service.files().get_media(fileId=file_id)\n",
        "  fh = io.BytesIO()\n",
        "  downloader = MediaIoBaseDownload(fh, request)\n",
        "  done = False\n",
        "  while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress()*100))\n",
        "  with open(child['name'], 'wb') as x:\n",
        "    x.write(fh.getvalue())"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Download 100%.\n",
            "Download 100%.\n",
            "Download 100%.\n",
            "Download 100%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6toU2xSRNL_e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    '''\n",
        "    :param text: a doc with multiple sentences, type: str\n",
        "    return a word list, type: list\n",
        "    https://textminingonline.com/dive-into-nltk-part-ii-sentence-tokenize-and-word-tokenize\n",
        "    e.g.\n",
        "    Input: 'It is a nice day. I am happy.'\n",
        "    Output: ['it', 'is', 'a', 'nice', 'day', 'i', 'am', 'happy']\n",
        "    '''\n",
        "    tokens = []\n",
        "    for word in nltk.word_tokenize(text):\n",
        "        word = word.lower()\n",
        "        if word not in stop_words and not word.isnumeric():\n",
        "            tokens.append(word)\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C5qx1NvrNL_h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_sequence(data, seq_length, vocab_dict):\n",
        "    '''\n",
        "    :param data: a list of words, type: list\n",
        "    :param seq_length: the length of sequences,, type: int\n",
        "    :param vocab_dict: a dict from words to indices, type: dict\n",
        "    return a dense sequence matrix whose elements are indices of words,\n",
        "    '''\n",
        "    data_matrix = np.zeros((len(data), seq_length), dtype=int)\n",
        "    for i, doc in enumerate(data):\n",
        "        for j, word in enumerate(doc):\n",
        "            # YOUR CODE HERE\n",
        "            if j == seq_length:\n",
        "                break\n",
        "            word_idx = vocab_dict.get(word, 1) # 1 means the unknown word\n",
        "            data_matrix[i, j] = word_idx\n",
        "    return data_matrix\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GCSnxy3RNL_k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_data(file_name, input_length, vocab=None):\n",
        "    \"\"\"\n",
        "    https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(file_name, engine='python')\n",
        "    df['words'] = df['text'].apply(tokenize)\n",
        "\n",
        "    if vocab is None:\n",
        "        vocab = set()\n",
        "        for i in range(len(df)):\n",
        "            for word in df.iloc[i]['words']:\n",
        "                vocab.add(word)\n",
        "    vocab_dict = dict()\n",
        "    vocab_dict['<pad>'] = 0 # 0 means the padding signal\n",
        "    vocab_dict['<unk>'] = 1 # 1 means the unknown word\n",
        "    vocab_size = 2\n",
        "    for v in vocab:\n",
        "        vocab_dict[v] = vocab_size\n",
        "        vocab_size += 1\n",
        "\n",
        "    data_matrix = get_sequence(df['words'], input_length, vocab_dict)\n",
        "    stars = df['stars'].apply(int) - 1\n",
        "    \n",
        "    \n",
        "    cool = np.array(preprocessing.minmax_scale(df['cool'].tolist()))\n",
        "    funny = np.array(preprocessing.minmax_scale(df['funny'].tolist()))\n",
        "    useful = np.array(preprocessing.minmax_scale(df['useful'].tolist()))\n",
        "    \n",
        "    features = np.vstack([cool, funny, useful]).T\n",
        "\n",
        "    return df['review_id'], stars, data_matrix, vocab, features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mklziUolNL_m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_length = 300\n",
        "embedding_size = 300\n",
        "hidden_size = 100\n",
        "batch_size = 100\n",
        "dropout_rate = 0.5\n",
        "learning_rate = 0.1\n",
        "total_epoch = 10\n",
        "\n",
        "filters = 150\n",
        "padding = 'valid'\n",
        "activation = 'relu'\n",
        "strides = 1\n",
        "pool_size = 2\n",
        "kernel_sizes = [3, 4, 5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t1ngJsOcNL_p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load training data and vocab\n",
        "train_id_list, train_data_label, train_data_matrix, vocab, train_features = read_data(\"train.csv\", input_length)\n",
        "K = max(train_data_label)+1  # labels begin with 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vLbBk3XNNL_s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_id_list, valid_data_label, valid_data_matrix, vocab, valid_features = read_data(\"valid.csv\", input_length, vocab=vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tRkcqZiXNL_v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_id_list, _, test_data_matrix, _, test_features = read_data(\"test.csv\", input_length, vocab=vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ga0jxYxtNL_y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Vocabulary Size:\", len(vocab))\n",
        "print(\"Training Set Size:\", len(train_id_list))\n",
        "print(\"Validation Set Size:\", len(valid_id_list))\n",
        "print(\"Test Set Size:\", len(test_id_list))\n",
        "print(\"Training Set Shape:\", train_data_matrix.shape)\n",
        "print(\"Validation Set Shape:\", valid_data_matrix.shape)\n",
        "print(\"Testing Set Shape:\", test_data_matrix.shape)\n",
        "print(\"Training Features:\", train_features.shape)\n",
        "print(\"Valid Features:\", valid_features.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m7N7js-RNL_2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data_label = keras.utils.to_categorical(train_data_label, num_classes=K)\n",
        "valid_data_label = keras.utils.to_categorical(valid_data_label, num_classes=K)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0AHUOkHwNL_6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "N = train_data_matrix.shape[0]\n",
        "K = train_data_label.shape[1]\n",
        "\n",
        "input_size = len(vocab) + 2\n",
        "output_size = K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EqoaOS-QNL_8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "main_input = Input(shape=(input_length,), name='main_input')\n",
        "\n",
        "e = Embedding(input_dim=input_size, output_dim=embedding_size, input_length=input_length)(main_input)\n",
        "\n",
        "e_d = Dropout(dropout_rate)(e)\n",
        "\n",
        "e_d = Reshape((input_length, embedding_size//3, 3))(e_d)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-SWSmajuiyd4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "conv_blocks = []\n",
        "for kernel_size in kernel_sizes:\n",
        "        \n",
        "    conv = Conv2D(filters=filters, kernel_size=(kernel_size, embedding_size//6), padding=padding, activation=activation, strides=(strides, strides))(e_d)\n",
        "    maxpooling = MaxPool2D(pool_size=((input_length-kernel_size)//strides+1, 1))(conv)\n",
        "    flatten = Flatten()(maxpooling)\n",
        "    conv_blocks.append(flatten)\n",
        "    \n",
        "c = Concatenate()(conv_blocks) if len(kernel_sizes) > 1 else conv_blocks[0]\n",
        "c_d = Dropout(dropout_rate)(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cjRfR_O9izD3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lstm_out = CuDNNLSTM(units=hidden_size)(c_d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GvOvqhvnNMAA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auxiliary_input = Input(shape=(3,), name='features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zEY7dNk8waQ-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "lF24DGGhNMAD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = keras.layers.concatenate([c_d, auxiliary_input])\n",
        "\n",
        "main_output = Dense(K, activation='softmax', name='main_output')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ibUSREoYNMAG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gm_uemPDNMAI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7otFqiB5NMAM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit({'main_input':train_data_matrix, 'features':train_features}, {'main_output': train_data_label}, epochs=total_epoch, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kEPJiXaCNMAQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "datetime.datetime.strptime('28/10/2017  2:42:40 PM', '%d/%m/%Y %I:%M:%S %p').strftime('%A')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5hzrYf9I_pL6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_score = model.evaluate({'main_input':valid_data_matrix, 'features':valid_features}, {'main_output': valid_data_label}, batch_size=batch_size)\n",
        "print('Validation Loss: {}\\n Validation Accuracy: {}\\n'.format(valid_score[0], valid_score[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g6C4GCdAOs6d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}